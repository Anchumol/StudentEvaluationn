{"ast":null,"code":"var _s = $RefreshSig$();\n\nimport { useCallback } from 'react';\nimport { useHistory } from 'react-router';\nimport { useDispatch, useSelector } from 'react-redux';\nimport { INIT_MY_MODEL } from '../store/MyModelSlice';\nimport { SET_HAS_CHANGES } from '../store/AppDataSlice';\nimport map from 'lodash/map';\nimport find from 'lodash/find';\nimport uniq from 'lodash/uniq';\nimport sortBy from 'lodash/sortBy';\nimport filter from 'lodash/filter';\nimport shuffle from 'lodash/shuffle';\nimport flattenDeep from 'lodash/flattenDeep';\nimport { roundToTwo } from '../util/helper';\n/**\n * This hook enables the usage of a customised Linear Regression algorithm for the prediction of student grades based on the subject credits, in a declarative manner\n * @returns 2 functions build() and predict() for building the model and making predictions using the built model respectively\n */\n\nconst useRegression = () => {\n  _s();\n\n  const dispatch = useDispatch();\n  const history = useHistory();\n  const lrModel = useSelector(state => state.lrModel);\n  const results = useSelector(state => state.results);\n  const calculate = useCallback((intercept = 0, // Intercept\n  coEfficient = 0, // Co-Efficient (Slope)\n  inputFeature) => Number(intercept + coEfficient * inputFeature), []);\n  const train = useCallback((inputFeatureDataSet = [], // Array of Input Features (i.e. Subject Credits)\n  outputFeatureDataSet = [], // Array of Input Features (i.e. Scored Marks)\n  intercept = 0, // Intercept\n  coEfficient = 0, // Co-Efficient (Slope)\n  learningRate = 0.0001, // Learning Rate\n  iterations = 10000 // Number of Iterations\n  ) => {\n    // let error = [] // Array to calculate cost for each iteration\n    // let errorCost,\n    let costIntercept, costCoEfficient, // prediction,\n    partialWrtIntercept, partialWrtCoEfficient;\n\n    for (let itr = 0; itr < iterations; itr++) {\n      // errorCost = 0\n      costIntercept = 0;\n      costCoEfficient = 0;\n\n      for (let i = 0; i < inputFeatureDataSet.length; i++) {\n        // prediction = calculate(intercept, coEfficient, inputFeatureDataSet[ i ])\n        // errorCost = errorCost + Math.pow(outputFeatureDataSet[ i ] - prediction, 2)\n        for (let j = 0; j < inputFeatureDataSet.length; j++) {\n          partialWrtIntercept = -2 * (outputFeatureDataSet[j] - calculate(intercept, coEfficient, inputFeatureDataSet[j])); // Partial Derivative w.r.t. intercept\n\n          partialWrtCoEfficient = -2 * inputFeatureDataSet[j] * (outputFeatureDataSet[j] - calculate(intercept, coEfficient, inputFeatureDataSet[j])); // Partial Derivative w.r.t. coEfficient\n\n          costIntercept += partialWrtIntercept;\n          costCoEfficient += partialWrtCoEfficient;\n        }\n\n        intercept = intercept - learningRate * costIntercept;\n        coEfficient = coEfficient - learningRate * costCoEfficient;\n      } // error.push(errorCost)\n\n    }\n\n    return {\n      intercept,\n      coEfficient\n    };\n  }, [calculate]);\n  const test = useCallback((testingDataSet, inputFeature, intercept, coEfficient) => {\n    let dataSet = shuffle([...testingDataSet]);\n    let errors = map(dataSet, marks => Math.abs(marks - calculate(intercept, coEfficient, inputFeature)));\n    let mae = errors.reduce((prev, next) => prev + next, 0) / errors.length;\n    return roundToTwo(100 - mae);\n  }, [calculate]);\n  const build = useCallback(() => {\n    const flatResults = flattenDeep(map(results, ({\n      semResult\n    }) => map(semResult, ({\n      credits,\n      scoredMarks,\n      maxMarks\n    }) => ({\n      credits,\n      scoredMarks: scoredMarks / maxMarks * 100\n    }))));\n    const allCredits = sortBy(uniq(map(flatResults, ({\n      credits\n    }) => Number(credits))));\n    const model = [];\n    let dataSet, credits, scoredMarks, dataPoint;\n\n    for (let i = 0; i < allCredits.length; i++) {\n      dataSet = filter(flatResults, {\n        credits: allCredits[i]\n      });\n      credits = map(dataSet, ({\n        credits\n      }) => credits);\n      scoredMarks = map(dataSet, ({\n        scoredMarks\n      }) => scoredMarks);\n      dataPoint = train(credits, scoredMarks);\n      dataPoint = { ...dataPoint,\n        credits: allCredits[i],\n        accuracy: test(scoredMarks, allCredits[i], dataPoint.intercept, dataPoint.coEfficient)\n      };\n      model.push(dataPoint);\n    }\n\n    dispatch(INIT_MY_MODEL(model));\n    history.push('/report');\n    dispatch(SET_HAS_CHANGES(false));\n  }, [dispatch, results, train, test, history]);\n  const predict = useCallback(credits => {\n    const {\n      intercept,\n      coEfficient\n    } = find(lrModel, {\n      credits\n    });\n    return roundToTwo(calculate(intercept, coEfficient, credits));\n  }, [lrModel, calculate]);\n  return {\n    build,\n    predict\n  };\n};\n\n_s(useRegression, \"Uy5cyb5zKq/cWwuA/hGWap2/Hu8=\", false, function () {\n  return [useDispatch, useHistory, useSelector, useSelector];\n});\n\nexport default useRegression;","map":{"version":3,"sources":["C:/Users/Digital/Desktop/student eva/studentEvaluation/stat/src/hooks/useRegression.js"],"names":["useCallback","useHistory","useDispatch","useSelector","INIT_MY_MODEL","SET_HAS_CHANGES","map","find","uniq","sortBy","filter","shuffle","flattenDeep","roundToTwo","useRegression","dispatch","history","lrModel","state","results","calculate","intercept","coEfficient","inputFeature","Number","train","inputFeatureDataSet","outputFeatureDataSet","learningRate","iterations","costIntercept","costCoEfficient","partialWrtIntercept","partialWrtCoEfficient","itr","i","length","j","test","testingDataSet","dataSet","errors","marks","Math","abs","mae","reduce","prev","next","build","flatResults","semResult","credits","scoredMarks","maxMarks","allCredits","model","dataPoint","accuracy","push","predict"],"mappings":";;AAAA,SAASA,WAAT,QAA4B,OAA5B;AACA,SAASC,UAAT,QAA2B,cAA3B;AACA,SAASC,WAAT,EAAsBC,WAAtB,QAAyC,aAAzC;AACA,SAASC,aAAT,QAA8B,uBAA9B;AACA,SAASC,eAAT,QAAgC,uBAAhC;AACA,OAAOC,GAAP,MAAgB,YAAhB;AACA,OAAOC,IAAP,MAAiB,aAAjB;AACA,OAAOC,IAAP,MAAiB,aAAjB;AACA,OAAOC,MAAP,MAAmB,eAAnB;AACA,OAAOC,MAAP,MAAmB,eAAnB;AACA,OAAOC,OAAP,MAAoB,gBAApB;AACA,OAAOC,WAAP,MAAwB,oBAAxB;AACA,SAASC,UAAT,QAA2B,gBAA3B;AAEA;AACA;AACA;AACA;;AACA,MAAMC,aAAa,GAAG,MAAM;AAAA;;AACxB,QAAMC,QAAQ,GAAGb,WAAW,EAA5B;AACA,QAAMc,OAAO,GAAGf,UAAU,EAA1B;AACA,QAAMgB,OAAO,GAAGd,WAAW,CAACe,KAAK,IAAIA,KAAK,CAACD,OAAhB,CAA3B;AACA,QAAME,OAAO,GAAGhB,WAAW,CAACe,KAAK,IAAIA,KAAK,CAACC,OAAhB,CAA3B;AAEA,QAAMC,SAAS,GAAGpB,WAAW,CAAC,CAC1BqB,SAAS,GAAG,CADc,EACX;AACfC,EAAAA,WAAW,GAAG,CAFY,EAET;AACjBC,EAAAA,YAH0B,KAIzBC,MAAM,CAACH,SAAS,GAAIC,WAAW,GAAGC,YAA5B,CAJkB,EAI0B,EAJ1B,CAA7B;AAMA,QAAME,KAAK,GAAGzB,WAAW,CAAC,CACtB0B,mBAAmB,GAAG,EADA,EACI;AAC1BC,EAAAA,oBAAoB,GAAG,EAFD,EAEK;AAC3BN,EAAAA,SAAS,GAAG,CAHU,EAGP;AACfC,EAAAA,WAAW,GAAG,CAJQ,EAIL;AACjBM,EAAAA,YAAY,GAAG,MALO,EAKC;AACvBC,EAAAA,UAAU,GAAG,KANS,CAMH;AANG,OAOrB;AACD;AACA;AACA,QAAIC,aAAJ,EACIC,eADJ,EAEI;AACAC,IAAAA,mBAHJ,EAIIC,qBAJJ;;AAMA,SAAK,IAAIC,GAAG,GAAG,CAAf,EAAkBA,GAAG,GAAGL,UAAxB,EAAoCK,GAAG,EAAvC,EAA2C;AACvC;AACAJ,MAAAA,aAAa,GAAG,CAAhB;AACAC,MAAAA,eAAe,GAAG,CAAlB;;AAEA,WAAK,IAAII,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGT,mBAAmB,CAACU,MAAxC,EAAgDD,CAAC,EAAjD,EAAqD;AACjD;AACA;AAEA,aAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGX,mBAAmB,CAACU,MAAxC,EAAgDC,CAAC,EAAjD,EAAqD;AACjDL,UAAAA,mBAAmB,GAAG,CAAC,CAAD,IAAML,oBAAoB,CAAEU,CAAF,CAApB,GAA4BjB,SAAS,CAACC,SAAD,EAAYC,WAAZ,EAAyBI,mBAAmB,CAAEW,CAAF,CAA5C,CAA3C,CAAtB,CADiD,CACoE;;AACrHJ,UAAAA,qBAAqB,GAAI,CAAC,CAAD,GAAKP,mBAAmB,CAAEW,CAAF,CAAzB,IAAmCV,oBAAoB,CAAEU,CAAF,CAApB,GAA4BjB,SAAS,CAACC,SAAD,EAAYC,WAAZ,EAAyBI,mBAAmB,CAAEW,CAAF,CAA5C,CAAxE,CAAxB,CAFiD,CAEmG;;AAEpJP,UAAAA,aAAa,IAAIE,mBAAjB;AACAD,UAAAA,eAAe,IAAIE,qBAAnB;AACH;;AAEDZ,QAAAA,SAAS,GAAGA,SAAS,GAAIO,YAAY,GAAGE,aAAxC;AACAR,QAAAA,WAAW,GAAGA,WAAW,GAAIM,YAAY,GAAGG,eAA5C;AACH,OAnBsC,CAoBvC;;AACH;;AAED,WAAO;AACHV,MAAAA,SADG;AAEHC,MAAAA;AAFG,KAAP;AAIH,GA3CwB,EA2CtB,CAAEF,SAAF,CA3CsB,CAAzB;AA6CA,QAAMkB,IAAI,GAAGtC,WAAW,CAAC,CAACuC,cAAD,EAAiBhB,YAAjB,EAA+BF,SAA/B,EAA0CC,WAA1C,KAA0D;AAC/E,QAAIkB,OAAO,GAAG7B,OAAO,CAAC,CAAE,GAAG4B,cAAL,CAAD,CAArB;AACA,QAAIE,MAAM,GAAGnC,GAAG,CACZkC,OADY,EAEZE,KAAK,IAAIC,IAAI,CAACC,GAAL,CAASF,KAAK,GAAGtB,SAAS,CAACC,SAAD,EAAYC,WAAZ,EAAyBC,YAAzB,CAA1B,CAFG,CAAhB;AAIA,QAAIsB,GAAG,GAAGJ,MAAM,CAACK,MAAP,CAAc,CAACC,IAAD,EAAOC,IAAP,KAAgBD,IAAI,GAAGC,IAArC,EAA2C,CAA3C,IAAgDP,MAAM,CAACL,MAAjE;AACA,WAAOvB,UAAU,CAAC,MAAMgC,GAAP,CAAjB;AACH,GARuB,EAQrB,CAAEzB,SAAF,CARqB,CAAxB;AAUA,QAAM6B,KAAK,GAAGjD,WAAW,CAAC,MAAM;AAC5B,UAAMkD,WAAW,GAAGtC,WAAW,CAC3BN,GAAG,CACCa,OADD,EAEC,CAAC;AAAEgC,MAAAA;AAAF,KAAD,KACI7C,GAAG,CACC6C,SADD,EAEC,CAAC;AAAEC,MAAAA,OAAF;AAAWC,MAAAA,WAAX;AAAwBC,MAAAA;AAAxB,KAAD,MAAyC;AACrCF,MAAAA,OADqC;AAErCC,MAAAA,WAAW,EAAGA,WAAW,GAAGC,QAAf,GAA2B;AAFH,KAAzC,CAFD,CAHR,CADwB,CAA/B;AAcA,UAAMC,UAAU,GAAG9C,MAAM,CACrBD,IAAI,CACAF,GAAG,CACC4C,WADD,EAEC,CAAC;AAAEE,MAAAA;AAAF,KAAD,KAAiB5B,MAAM,CAAC4B,OAAD,CAFxB,CADH,CADiB,CAAzB;AASA,UAAMI,KAAK,GAAG,EAAd;AACA,QAAIhB,OAAJ,EAAaY,OAAb,EAAsBC,WAAtB,EAAmCI,SAAnC;;AACA,SAAK,IAAItB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGoB,UAAU,CAACnB,MAA/B,EAAuCD,CAAC,EAAxC,EAA4C;AACxCK,MAAAA,OAAO,GAAG9B,MAAM,CAACwC,WAAD,EAAc;AAAEE,QAAAA,OAAO,EAAEG,UAAU,CAAEpB,CAAF;AAArB,OAAd,CAAhB;AACAiB,MAAAA,OAAO,GAAG9C,GAAG,CAACkC,OAAD,EAAU,CAAC;AAAEY,QAAAA;AAAF,OAAD,KAAiBA,OAA3B,CAAb;AACAC,MAAAA,WAAW,GAAG/C,GAAG,CAACkC,OAAD,EAAU,CAAC;AAAEa,QAAAA;AAAF,OAAD,KAAqBA,WAA/B,CAAjB;AACAI,MAAAA,SAAS,GAAGhC,KAAK,CAAC2B,OAAD,EAAUC,WAAV,CAAjB;AACAI,MAAAA,SAAS,GAAG,EACR,GAAGA,SADK;AAERL,QAAAA,OAAO,EAAEG,UAAU,CAAEpB,CAAF,CAFX;AAGRuB,QAAAA,QAAQ,EAAEpB,IAAI,CAACe,WAAD,EAAcE,UAAU,CAAEpB,CAAF,CAAxB,EAA+BsB,SAAS,CAACpC,SAAzC,EAAoDoC,SAAS,CAACnC,WAA9D;AAHN,OAAZ;AAKAkC,MAAAA,KAAK,CAACG,IAAN,CAAWF,SAAX;AACH;;AACD1C,IAAAA,QAAQ,CAACX,aAAa,CAACoD,KAAD,CAAd,CAAR;AAEAxC,IAAAA,OAAO,CAAC2C,IAAR,CAAa,SAAb;AACA5C,IAAAA,QAAQ,CAACV,eAAe,CAAC,KAAD,CAAhB,CAAR;AACH,GA1CwB,EA0CtB,CAAEU,QAAF,EAAYI,OAAZ,EAAqBM,KAArB,EAA4Ba,IAA5B,EAAkCtB,OAAlC,CA1CsB,CAAzB;AA4CA,QAAM4C,OAAO,GAAG5D,WAAW,CAACoD,OAAO,IAAI;AACnC,UAAM;AAAE/B,MAAAA,SAAF;AAAaC,MAAAA;AAAb,QAA6Bf,IAAI,CAACU,OAAD,EAAU;AAAEmC,MAAAA;AAAF,KAAV,CAAvC;AACA,WAAOvC,UAAU,CAACO,SAAS,CAACC,SAAD,EAAYC,WAAZ,EAAyB8B,OAAzB,CAAV,CAAjB;AACH,GAH0B,EAGxB,CAAEnC,OAAF,EAAWG,SAAX,CAHwB,CAA3B;AAKA,SAAO;AACH6B,IAAAA,KADG;AAEHW,IAAAA;AAFG,GAAP;AAIH,CAxHD;;GAAM9C,a;UACeZ,W,EACDD,U,EACAE,W,EACAA,W;;;AAsHpB,eAAeW,aAAf","sourcesContent":["import { useCallback } from 'react'\nimport { useHistory } from 'react-router'\nimport { useDispatch, useSelector } from 'react-redux'\nimport { INIT_MY_MODEL } from '../store/MyModelSlice'\nimport { SET_HAS_CHANGES } from '../store/AppDataSlice'\nimport map from 'lodash/map'\nimport find from 'lodash/find'\nimport uniq from 'lodash/uniq'\nimport sortBy from 'lodash/sortBy'\nimport filter from 'lodash/filter'\nimport shuffle from 'lodash/shuffle'\nimport flattenDeep from 'lodash/flattenDeep'\nimport { roundToTwo } from '../util/helper'\n\n/**\n * This hook enables the usage of a customised Linear Regression algorithm for the prediction of student grades based on the subject credits, in a declarative manner\n * @returns 2 functions build() and predict() for building the model and making predictions using the built model respectively\n */\nconst useRegression = () => {\n    const dispatch = useDispatch()\n    const history = useHistory()\n    const lrModel = useSelector(state => state.lrModel)\n    const results = useSelector(state => state.results)\n\n    const calculate = useCallback((\n        intercept = 0, // Intercept\n        coEfficient = 0, // Co-Efficient (Slope)\n        inputFeature,\n    ) => Number(intercept + (coEfficient * inputFeature)), [])\n\n    const train = useCallback((\n        inputFeatureDataSet = [], // Array of Input Features (i.e. Subject Credits)\n        outputFeatureDataSet = [], // Array of Input Features (i.e. Scored Marks)\n        intercept = 0, // Intercept\n        coEfficient = 0, // Co-Efficient (Slope)\n        learningRate = 0.0001, // Learning Rate\n        iterations = 10000 // Number of Iterations\n    ) => {\n        // let error = [] // Array to calculate cost for each iteration\n        // let errorCost,\n        let costIntercept,\n            costCoEfficient,\n            // prediction,\n            partialWrtIntercept,\n            partialWrtCoEfficient\n\n        for (let itr = 0; itr < iterations; itr++) {\n            // errorCost = 0\n            costIntercept = 0\n            costCoEfficient = 0\n\n            for (let i = 0; i < inputFeatureDataSet.length; i++) {\n                // prediction = calculate(intercept, coEfficient, inputFeatureDataSet[ i ])\n                // errorCost = errorCost + Math.pow(outputFeatureDataSet[ i ] - prediction, 2)\n\n                for (let j = 0; j < inputFeatureDataSet.length; j++) {\n                    partialWrtIntercept = -2 * (outputFeatureDataSet[ j ] - calculate(intercept, coEfficient, inputFeatureDataSet[ j ])) // Partial Derivative w.r.t. intercept\n                    partialWrtCoEfficient = (-2 * inputFeatureDataSet[ j ]) * (outputFeatureDataSet[ j ] - calculate(intercept, coEfficient, inputFeatureDataSet[ j ])) // Partial Derivative w.r.t. coEfficient\n\n                    costIntercept += partialWrtIntercept\n                    costCoEfficient += partialWrtCoEfficient\n                }\n\n                intercept = intercept - (learningRate * costIntercept)\n                coEfficient = coEfficient - (learningRate * costCoEfficient)\n            }\n            // error.push(errorCost)\n        }\n\n        return {\n            intercept,\n            coEfficient,\n        }\n    }, [ calculate ])\n\n    const test = useCallback((testingDataSet, inputFeature, intercept, coEfficient) => {\n        let dataSet = shuffle([ ...testingDataSet ])\n        let errors = map(\n            dataSet,\n            marks => Math.abs(marks - calculate(intercept, coEfficient, inputFeature))\n        )\n        let mae = errors.reduce((prev, next) => prev + next, 0) / errors.length\n        return roundToTwo(100 - mae)\n    }, [ calculate ])\n\n    const build = useCallback(() => {\n        const flatResults = flattenDeep(\n            map(\n                results,\n                ({ semResult }) =>\n                    map(\n                        semResult,\n                        ({ credits, scoredMarks, maxMarks }) => ({\n                            credits,\n                            scoredMarks: (scoredMarks / maxMarks) * 100\n                        })\n                    )\n            )\n        )\n\n        const allCredits = sortBy(\n            uniq(\n                map(\n                    flatResults,\n                    ({ credits }) => Number(credits)\n                )\n            )\n        )\n\n        const model = []\n        let dataSet, credits, scoredMarks, dataPoint\n        for (let i = 0; i < allCredits.length; i++) {\n            dataSet = filter(flatResults, { credits: allCredits[ i ] })\n            credits = map(dataSet, ({ credits }) => credits)\n            scoredMarks = map(dataSet, ({ scoredMarks }) => scoredMarks)\n            dataPoint = train(credits, scoredMarks)\n            dataPoint = {\n                ...dataPoint,\n                credits: allCredits[ i ],\n                accuracy: test(scoredMarks, allCredits[ i ], dataPoint.intercept, dataPoint.coEfficient),\n            }\n            model.push(dataPoint)\n        }\n        dispatch(INIT_MY_MODEL(model))\n\n        history.push('/report')\n        dispatch(SET_HAS_CHANGES(false))\n    }, [ dispatch, results, train, test, history ])\n\n    const predict = useCallback(credits => {\n        const { intercept, coEfficient } = find(lrModel, { credits })\n        return roundToTwo(calculate(intercept, coEfficient, credits))\n    }, [ lrModel, calculate ])\n\n    return {\n        build,\n        predict,\n    }\n}\n\nexport default useRegression"]},"metadata":{},"sourceType":"module"}